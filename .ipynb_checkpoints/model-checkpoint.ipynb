{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af567386-255b-4c5e-87d7-7412ba82c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"./data/training_data.csv\", header=None)\n",
    "\n",
    "print(df.shape)   # rows x columns\n",
    "print(df.head())\n",
    "\n",
    "MAX_LEN = 640\n",
    "\n",
    "# Convert each row to numpy array and pad\n",
    "data = []\n",
    "\n",
    "for row in df.values:\n",
    "    # Convert all items to numeric (invalid → NaN)\n",
    "    row = pd.to_numeric(row, errors='coerce')\n",
    "\n",
    "    # Drop NaNs\n",
    "    row = row[~np.isnan(row)]\n",
    "\n",
    "    # Convert to float32\n",
    "    row = row.astype(np.float32)\n",
    "\n",
    "    # Pad\n",
    "    if len(row) < MAX_LEN:\n",
    "        padded = np.pad(row, (0, MAX_LEN - len(row)), constant_values=0)\n",
    "    else:\n",
    "        padded = row[:MAX_LEN]\n",
    "\n",
    "    data.append(padded)\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "\n",
    "# Remove any leftover inf/NaN\n",
    "data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(np.isnan(data).any())   # should be False\n",
    "print(np.isinf(data).any())   # should be False\n",
    "\n",
    "print(data.shape)  # (num_samples, 640)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Example: last column is label, rest are features\n",
    "# First column is the label\n",
    "y = data[:, 0].astype(int)   # labels (0 or 1)\n",
    "X = data[:, 1:]              # features (639 columns after padding)\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Wrap in DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim=639, hidden_dim=128, output_dim=2):  # <-- 2 classes\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleModel(input_dim=639, hidden_dim=128, output_dim=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):  # 10 epochs\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "MAX_LEN = 640       # same as before\n",
    "FEATURES = 639      # model input size\n",
    "\n",
    "# Load your 1-row CSV (no label column)\n",
    "row = pd.read_csv(\"./data/test_one.csv\", header=None).values.flatten()\n",
    "\n",
    "# Convert to numeric\n",
    "row = pd.to_numeric(row, errors='coerce')\n",
    "\n",
    "# Remove NaNs\n",
    "row = row[~np.isnan(row)]\n",
    "\n",
    "# Convert to float32\n",
    "row = row.astype(np.float32)\n",
    "row = np.nan_to_num(row, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Pad to 639 features + 1 label position (but label is missing)\n",
    "# Training format = [label | 639 features]\n",
    "# Here we only have the 639 features, so if row is shorter → pad to 639\n",
    "if len(row) < FEATURES:\n",
    "    row = np.pad(row, (0, FEATURES - len(row)), constant_values=0)\n",
    "\n",
    "row = scaler.transform([row])  # keep 2D shape\n",
    "tensor_row = torch.tensor(row, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(tensor_row)           # shape: [1, 2] for 2 classes\n",
    "    probs = F.softmax(output, dim=1)\n",
    "\n",
    "percent_class_0 = probs[0][0].item() * 100\n",
    "percent_class_1 = probs[0][1].item() * 100\n",
    "\n",
    "print(f\"Class 0 chance: {percent_class_0:.2f}%\")\n",
    "print(f\"Class 1 chance: {percent_class_1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4b2123-aea4-4cca-8f90-8746493a634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 640)\n",
      "   0    1    2    3    4    5            6    7    8    9    ...  630  631  \\\n",
      "0  1.0    1    1    1    1    1  75712099.05    1    1    1  ...  0.0  0.0   \n",
      "1  1.0    1    1    1    1    1  47189363.60    1    1    1  ...  NaN  NaN   \n",
      "2  0.0    1    1    1    1    1  19763851.20    1    1    1  ...  NaN  NaN   \n",
      "3  1.0    1    1    1    1    1  12688293.50    1    1    1  ...  NaN  NaN   \n",
      "4  1.0    1    1    1    1    1  12056225.30    1    1    1  ...  NaN  NaN   \n",
      "\n",
      "   632  633  634  635  636     637   638  639  \n",
      "0  0.0  0.0  0.0  0.0  0.0  402.43  42.0  1.0  \n",
      "1  NaN  NaN  NaN  NaN  NaN     NaN   NaN  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN     NaN   NaN  NaN  \n",
      "3  NaN  NaN  NaN  NaN  NaN     NaN   NaN  NaN  \n",
      "4  NaN  NaN  NaN  NaN  NaN     NaN   NaN  NaN  \n",
      "\n",
      "[5 rows x 640 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fab7979-ebf6-4735-907f-e3877907d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(97, 640)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cdb70e5-9578-4f66-9c9a-1bab2407a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7424\n",
      "Epoch 2, Loss: 0.6199\n",
      "Epoch 3, Loss: 0.5987\n",
      "Epoch 4, Loss: 0.4569\n",
      "Epoch 5, Loss: 0.4317\n",
      "Epoch 6, Loss: 0.4924\n",
      "Epoch 7, Loss: 0.4170\n",
      "Epoch 8, Loss: 0.3005\n",
      "Epoch 9, Loss: 0.4240\n",
      "Epoch 10, Loss: 0.3465\n",
      "Epoch 11, Loss: 0.3814\n",
      "Epoch 12, Loss: 0.3704\n",
      "Epoch 13, Loss: 0.4220\n",
      "Epoch 14, Loss: 0.2925\n",
      "Epoch 15, Loss: 0.2612\n",
      "Epoch 16, Loss: 0.2929\n",
      "Epoch 17, Loss: 0.2283\n",
      "Epoch 18, Loss: 0.1932\n",
      "Epoch 19, Loss: 0.2571\n",
      "Epoch 20, Loss: 0.2037\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33ffea4-e2b3-4231-81ac-c24ca540eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 chance: 0.00%\n",
      "Class 1 chance: 100.00%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015b481-762a-467a-9ebf-54c64ef5b702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0ffdc-b3f2-4617-81d4-867fcc805d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
